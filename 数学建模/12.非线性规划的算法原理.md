# 非线性规划的求解方法

在线性规划的基础上，目标函数可以非线性，约束条件可以非线性，包括非线性的等式和不等式。
$$
\min f(x) \\
\begin{cases}
Ax \le B \\
Aeq \cdot = Beq \\
C(x) \le 0 \\
Ceq(x) = 0
\end{cases}
$$
目标函数形式如果是一个二次函数那就是一个二次规划：
$$
\min f = 2x_1^2 + 3 x_1 x_3 - x_2^2 \\
s.t.
\begin{cases}
x_1^2 - 2x_2 + 3x_3 = 4 \\
x_1 + x_2 - x_3 \le 6 \\
2x_1 - x_2 + x_3 \le 15 \\
x_1,\ x_2,\ x_3 > 0
\end{cases}
$$

- 无约束极值求解：==解偏导数方程组==

当我们碰上了有约束条件下的非线性函数求极值的时候，我们通常使用拉格朗日法。例如，对于广义的含等式条件（先暂时只考虑等式问题）的极值问题：
$$
\min f(x) \\
s.t.
\begin{cases}
C_1(x) = 0 \\
C_2(x) = 0 \\
\quad \quad \vdots \\
C_n(x) = 0
\end{cases}
$$
在数学最优问题中，拉格朗日乘子法（Lagrange Multiplier，以数学家拉格朗日命名）是一种寻找变量受一个或多个条件限制的多元函数的极值的方法。

这种方法将一个有 $n$ 个变量与 $k$ 个约束条件的最优化问题转换为一个有 $n+k$ 个变量的方程组的极值问题，其变量不受任何约束，这种方法引I入了一种新的标量未知数，即拉格朗日乘数：约束方程的梯度（gradient）白的线性组合里每个向量的系数。
$$
\min L(x,\ \lambda) = f(x) + \lambda_1 C_1(x) + \lambda_2 C_2(x) + \dots + \lambda_n C_n(x)
$$
设目标函数 $f(x)$，不等式约束为 $g(x)$，有的加上等式约束 $h(x)$。此时约束优化问题描述如下：
$$
\min f(x) \\
s.t.
\begin{cases}
h(x) = 0 \\
g(x) \le 0
\end{cases}
$$

$$
L(x,\ \lambda,\ \mu) = f(x) + \lambda h(x) + \mu g(x) \\
\begin{cases}
\left.\dfrac{\partial L}{\partial X}\right|_{X = X^*} = 0 \\
\lambda \ne 0 \\
\mu \ge 0 \\
\mu g(X^*) = 0 \\
h(X^*) = 0 \\
g(X^*) \le 0
\end{cases}
$$

---

在 *Python* 中，使用 `scipy.optimize` 模块解决线性规划问题：

- `brent()`：单变量无约束优化问题，混合使用牛顿法/二分法；
- `fmin()`：多变量无约束优化问题，使用单纯性法，只利用函数值，不需要函数的导数或二阶导数；
- `leatsq()`：非线性最小二乘问题，用于求解非线性最小二乘拟合问题；
- `minimize`：约束优化问题，使用拉格朗日乘子法将约束条件优化转为无约束条件优化问题。

<img src="https://leafalice-image.oss-cn-hangzhou.aliyuncs.com/img/2024-04-03%2Fb494fee2eb7bd2893ad4e9b22065b394--dcf2--image-20240403092028052.png" alt="image-20240403092028052" style="zoom:67%;" />

<img src="https://leafalice-image.oss-cn-hangzhou.aliyuncs.com/img/2024-04-03%2F22b38c4eb3657d04acc5aa9f604b6dc0--2d31--image-20240403092205040.png" alt="image-20240403092205040" style="zoom: 67%;" />

<img src="https://leafalice-image.oss-cn-hangzhou.aliyuncs.com/img/2024-04-03%2Ff4576edfe6d61a400d4aca8313f118ca--00c5--image-20240403092309621.png" alt="image-20240403092309621" style="zoom:67%;" />

*蒙特卡洛方法*就是在==可行域范围内生成大批量随机数据点==，观测这些些数据点在什么位置取得近似最优。但是生成点因是随机的，所以生成大批量数据去做计算的然后求出的是数值的近似最优解，更多的适用于解非线性问题，线性问题是能得到准确解的。

<img src="https://leafalice-image.oss-cn-hangzhou.aliyuncs.com/img/2024-04-03%2F0498be26c3d269796f2a05314a35751e--c15b--image-20240403092630197.png" alt="image-20240403092630197" style="zoom:67%;" />

---

`optimize.brent()` 的主要参数：

- `func`：`callble f(x, *args)` 目标函数，以函数形式表示，可以通过 `*arg` 传递参数；
- `args`：`tuple` 可选项，以 `f(x, *args)` 的形式将可变参数 `p` 传递给目标函数；
- `brack`：`tuple` 可选项，搜索算法的开始区间（不是指 `x` 的上下限）

`optimize.brent()` 的主要返回值：

- `xmin`：返回函数达到最小值式的 `x`（注意是局部最优，不一定是全局最优）。
- `fval`：返回函数的最优值（默认不返回，仅当 `full_output` 为 1 时返回）。

```python
# 1. Demo1: 单变量无约束优化问题
def func(x):  # 目标函数
    f = x**2 - 8 * np.sin(2 * x + np.pi)
    return f


x_ini = -5.0
x_opt = brent(func, brack=(x_ini, 2))
print(f"x_ini = {x_ini: .4f}\tf(x_ini) = {func(x_ini): .4f}")
print(f"x_opt = {x_opt: .4f}\tf(x_opt) = {func(x_opt): .4f}")
```

```shell
x_ini = -5.0000	f(x_ini) =  29.3522
x_opt = -0.7391	f(x_opt) = -7.4195
```

---

`optimize.fmin()` 的主要参数：

- `func`：`callble f(x, *args)` 目标函数，以函数形式表示，可以通过 `*arg` 传递参数；
- `x0`：`nadarray` 搜索算法的初值
- `args`：`tuple` 可选项，以 `f(x, *args)` 的形式将可变参数 `p` 传递给目标函数；

`optimize.fmin()` 的主要返回值：

- `xmin`：返回函数达到最小值式的 `x` 值。
- `fopt`：返回最小值时的目标函数值，`f_opt = func(x_opt)`。

```python
# 2. Demo2: 多变量无约束优化问题
def func(x):
    f = 100.0 * (x[0] - x[1] ** 2.0) ** 2.0 + (1.0 - x[1]) ** 2.0
    return f


x_ini = np.array([-2, 2])
x_opt = fmin(func, x_ini)
print(f"x_ini = {x_ini}\tf(x_ini) = {func(x_ini): .4f}")
print(f"x_opt = {x_opt}\tf(x_opt) = {func(x_opt): .4f}")
```

```shell
Optimization terminated successfully.
         Current function value: 0.000000
         Iterations: 88
         Function evaluations: 164
x_ini = [-2  2]	f(x_ini) =  3601.0000
x_opt = [1.00000048 1.00000196]	f(x_opt) =  0.0000

```

---

<img src="https://leafalice-image.oss-cn-hangzhou.aliyuncs.com/img/2024-04-03%2F4f5f79622c4323b01dcda542a99ce510--3592--image-20240403104542852.png" alt="image-20240403104542852" style="zoom:80%;" />

<img src="https://leafalice-image.oss-cn-hangzhou.aliyuncs.com/img/2024-04-03%2Ffe2b943355458d28071261650c969d05--338f--image-20240403104642059.png" alt="image-20240403104642059" style="zoom:80%;" />

```python
# 3. Demo3: 多变量边界约束优化问题


# 目标函数
def fun(args):
    f = lambda x: 60 - 10 * x[0] - 4 * x[1] + x[0] ** 2 + x[1] ** 2 - x[0] * x[1]
    return f


# 约束条件，包括等式约束和不等式约束
def con(args):
    cons = {"type": "eq", "fun": lambda x: x[0] + x[1] - 8}
    return cons


args1 = ()
args2 = ()
# 设置初始值，初始值的设置很重要，很容易收敛到另外的极值点中，可多次尝试
cons = con(args2)
x0 = np.array((2.0, 1.0))

res = minimize(fun(args1), x0, method="SLSQP", constraints=cons)
print(res)
```

```shell
 message: Optimization terminated successfully
 success: True
  status: 0
     fun: 17.000000000000007
       x: [ 5.000e+00  3.000e+00]
     nit: 4
     jac: [-3.000e+00 -3.000e+00]
    nfev: 12
    njev: 4
```

```python
def func(x):
    func = x[0] ** 2 + 2 * x[1] ** 2 + 3 * x[2] ** 2 + 8
    return func


def con1(x):
    return x[0] ** 2 - x[1] + x[2] ** 2


def con2(x):
    return -(x[0] + x[1] ** 2 + x[2] ** 3 - 20)


def con3(x):
    return -x[0] - x[1] ** 2 + 2


def con4(x):
    return x[1] + 2 * x[2] ** 2 - 3


bounds = np.array(3 * [(0.0, None)])
constraints = np.array(
    [
        {"type": "ineq", "fun": con1},
        {"type": "ineq", "fun": con2},
        {"type": "eq", "fun": con3},
        {"type": "eq", "fun": con4},
    ]
)

x0 = np.array([1.0, 2.0, 3.0])
res = minimize(func, x0, method="SLSQP", bounds=bounds, constraints=constraints)
res
```

```shell
 message: Optimization terminated successfully
 success: True
  status: 0
     fun: 13.878994794550533
       x: [ 6.743e-01  1.151e+00  9.614e-01]
     nit: 7
     jac: [ 1.349e+00  4.606e+00  5.768e+00]
    nfev: 28
    njev: 7
```

